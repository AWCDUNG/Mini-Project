{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AWCDUNG/Mini-Project/blob/main/Colaboratory_ch%C3%A0o_m%E1%BB%ABng_b%E1%BA%A1n!.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyspark"
      ],
      "metadata": {
        "id": "-_w0t3Ju8bmU",
        "outputId": "f195cfdf-defa-4ef2-8434-d0ba2d81de86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.4)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create SparkSession from builder master(\"local[1]\") \\\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[1]\") \\\n",
        "                    .appName('PySparkLesson2.com') \\\n",
        "                    .config(\"spark.memory.offHeap.enabled\",\"true\") \\\n",
        "                    .config(\"spark.memory.offHeap.size\",\"10g\")\\\n",
        "                    .getOrCreate()"
      ],
      "metadata": {
        "id": "wLZZLNx78ckM"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark2 = SparkSession.newSession\n",
        "print(spark2)"
      ],
      "metadata": {
        "id": "js58vwsH8cnU",
        "outputId": "1e82c84f-70ea-461a-93ae-5e14416fc753",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<function SparkSession.newSession at 0x7ebaa8bc1ea0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get Existing SparkSession\n",
        "spark3 = SparkSession.builder.getOrCreate\n",
        "print(spark3)"
      ],
      "metadata": {
        "id": "bCenBcQg8cpr",
        "outputId": "c1f562cb-2a68-4ff7-a603-8d8770d9ce73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method SparkSession.Builder.getOrCreate of <pyspark.sql.session.SparkSession.Builder object at 0x7eba72689b70>>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Usage of config()\n",
        "spark3 = SparkSession.builder \\\n",
        "      .master(\"local[1]\") \\\n",
        "      .appName(\"PySparkLesson2.com\") \\\n",
        "      .config(\"spark.some.config.option\", \"config-value\") \\\n",
        "      .getOrCreate()"
      ],
      "metadata": {
        "id": "_cZ9RS7L8csj"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a Spark Config\n",
        "partitions = spark.conf.get(\"spark.sql.shuffle.partitions\")\n",
        "print(partitions)"
      ],
      "metadata": {
        "id": "U6ujb3Jx8cvb",
        "outputId": "6d289710-230a-4669-817f-edc9316935a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrame\n",
        "df = spark.createDataFrame(\n",
        "    [(\"Scala\", 25000), (\"Spark\", 35000), (\"PHP\", 21000)])\n",
        "df.show()"
      ],
      "metadata": {
        "id": "SS4FS_hn_bGP",
        "outputId": "f5906208-3b9b-42d5-a2c4-3b45500d0330",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+\n",
            "|   _1|   _2|\n",
            "+-----+-----+\n",
            "|Scala|25000|\n",
            "|Spark|35000|\n",
            "|  PHP|21000|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get metadata from the Catalog\n",
        "# List databases\n",
        "dbs = spark.catalog.listDatabases()\n",
        "print(dbs)"
      ],
      "metadata": {
        "id": "4qwz_0MH_bEA",
        "outputId": "c22b7f6a-3375-487b-b6bd-d01c168f1a20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Database(name='default', catalog='spark_catalog', description='default database', locationUri='file:/content/spark-warehouse')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List Tables\n",
        "tbls = spark.catalog.listTables()\n",
        "print(tbls)"
      ],
      "metadata": {
        "id": "gZ-2lsBL_bB7",
        "outputId": "4c027e4d-493d-47b6-906c-d8a6961424cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create RDD from parallelize\n",
        "data = [1,2,3,4,5,6,7,8,9,10,11,12]\n",
        "rdd=spark.sparkContext.parallelize(data)\n",
        "rdd"
      ],
      "metadata": {
        "id": "JDnCEkB3_a_p",
        "outputId": "6631082f-5243-4575-c0d7-f3f3f287549d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ParallelCollectionRDD[389] at readRDDFromFile at PythonRDD.scala:289"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create RDD from external Data source\n",
        "rdd2 = spark.sparkContext.textFile(\"/content/drive/MyDrive/test.txt\")\n",
        "rdd2"
      ],
      "metadata": {
        "id": "D8yRZpxd_a9T",
        "outputId": "11c415f3-a9a7-4ee9-c9ea-ef7b6995f32b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "/content/drive/MyDrive/test.txt MapPartitionsRDD[401] at textFile at <unknown>:0"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creates empty RDD with no partition\n",
        "rdd = spark.sparkContext.emptyRDD\n",
        "# rddString = spark.sparkContext.emptyRDD[String]\n"
      ],
      "metadata": {
        "id": "A491W_qQ_a7A"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create empty RDD with partition\n",
        "rdd2 = spark.sparkContext.parallelize([],10) #This creates 10 partitions\n",
        "\n",
        "rdd = spark.sparkContext.textFile(\"/content/drive/MyDrive/test.txt\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ixZdojwo_a48"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rdd2 = rdd.flatMap(lambda x: x.split(\" \"))\n",
        "\n",
        "rdd3 = rdd2.map(lambda x: (x,1))\n",
        "\n",
        "rdd4 = rdd3.reduceByKey(lambda a,b: a+b)\n",
        "\n",
        "rdd5 = rdd4.map(lambda x: (x[1],x[0])).sortByKey()\n",
        "#Print rdd5 result to console\n",
        "print(rdd5.collect())\n"
      ],
      "metadata": {
        "id": "2dO1ns8v_a2p",
        "outputId": "e06e7935-4254-4def-c70d-bc8077a3aec8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(9, 'Project'), (9, 'Gutenberg’s'), (18, 'Alice’s'), (18, 'Adventures'), (18, 'in'), (18, 'Wonderland'), (18, 'by'), (18, 'Lewis'), (18, 'Carroll'), (27, 'This'), (27, 'eBook'), (27, 'is'), (27, 'for'), (27, 'the'), (27, 'use'), (27, 'of'), (27, 'anyone'), (27, 'anywhere'), (27, 'at'), (27, 'no'), (27, 'cost'), (27, 'and'), (27, 'with')]\n",
            "Count : 23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd4 = rdd3.filter(lambda x : 'an' in x[0])\n",
        "print(rdd4.collect())"
      ],
      "metadata": {
        "id": "sGewYgF_BL4Z",
        "outputId": "54abfd7e-6a5d-4c1c-d1b6-7d3d61863e79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Wonderland', 1), ('anyone', 1), ('anywhere', 1), ('and', 1), ('Wonderland', 1), ('anyone', 1), ('anywhere', 1), ('and', 1), ('anyone', 1), ('anywhere', 1), ('and', 1), ('Wonderland', 1), ('anyone', 1), ('anywhere', 1), ('and', 1), ('Wonderland', 1), ('anyone', 1), ('anywhere', 1), ('and', 1), ('anyone', 1), ('anywhere', 1), ('and', 1), ('Wonderland', 1), ('anyone', 1), ('anywhere', 1), ('and', 1), ('Wonderland', 1), ('anyone', 1), ('anywhere', 1), ('and', 1), ('anyone', 1), ('anywhere', 1), ('and', 1), ('Wonderland', 1), ('anyone', 1), ('anywhere', 1), ('and', 1), ('Wonderland', 1), ('anyone', 1), ('anywhere', 1), ('and', 1), ('anyone', 1), ('anywhere', 1), ('and', 1), ('Wonderland', 1), ('anyone', 1), ('anywhere', 1), ('and', 1), ('Wonderland', 1), ('anyone', 1), ('anywhere', 1), ('and', 1), ('anyone', 1), ('anywhere', 1), ('and', 1), ('Wonderland', 1), ('anyone', 1), ('anywhere', 1), ('and', 1), ('Wonderland', 1), ('anyone', 1), ('anywhere', 1), ('and', 1), ('anyone', 1), ('anywhere', 1), ('and', 1), ('Wonderland', 1), ('anyone', 1), ('anywhere', 1), ('and', 1), ('Wonderland', 1), ('anyone', 1), ('anywhere', 1), ('and', 1), ('anyone', 1), ('anywhere', 1), ('and', 1), ('Wonderland', 1), ('anyone', 1), ('anywhere', 1), ('and', 1), ('Wonderland', 1), ('anyone', 1), ('anywhere', 1), ('and', 1), ('anyone', 1), ('anywhere', 1), ('and', 1), ('Wonderland', 1), ('anyone', 1), ('anywhere', 1), ('and', 1), ('Wonderland', 1), ('anyone', 1), ('anywhere', 1), ('and', 1), ('anyone', 1), ('anywhere', 1), ('and', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Count : \"+str(rdd5.count()))"
      ],
      "metadata": {
        "id": "t8UMimqC_a0V",
        "outputId": "797b9107-697d-41ff-eb2a-5fbe8cc43ae1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count : 23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "firstRec = rdd5.first()\n",
        "print(\"First Record : \"+str(firstRec[0]) + \",\"+ firstRec[1])\n",
        "\n",
        "datMax = rdd5.max()\n",
        "print(\"Max Record : \"+str(datMax[0]) + \",\"+ datMax[1])\n",
        "\n",
        "totalWordCount = rdd5.reduce(lambda a,b: (a[0]+b[0],a[1]))\n",
        "print(\"dataReduce Record : \"+str(totalWordCount[0]))"
      ],
      "metadata": {
        "id": "j6gL2oXH_ayK",
        "outputId": "ee3ceb96-d7f5-4de5-8f8f-fc32a07bc987",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Record : 9,Project\n",
            "Max Record : 27,with\n",
            "dataReduce Record : 522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data3 = rdd5.take(3)\n",
        "for f in data3:\n",
        "    print(\"data3 Key:\"+ str(f[0]) +\", Value:\"+f[1])"
      ],
      "metadata": {
        "id": "EVdyXMQj_avo",
        "outputId": "dcc7b1cb-aa5c-4985-bc4b-b85a99740076",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data3 Key:9, Value:Project\n",
            "data3 Key:9, Value:Gutenberg’s\n",
            "data3 Key:18, Value:Alice’s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = rdd5.collect()\n",
        "for f in data:\n",
        "    print(\"Key:\"+ str(f[0]) +\", Value:\"+f[1])\n"
      ],
      "metadata": {
        "id": "P-0zRbhb_atS",
        "outputId": "0d55da47-c662-46ae-fd4d-be0e4f198e56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Key:9, Value:Project\n",
            "Key:9, Value:Gutenberg’s\n",
            "Key:18, Value:Alice’s\n",
            "Key:18, Value:Adventures\n",
            "Key:18, Value:in\n",
            "Key:18, Value:Wonderland\n",
            "Key:18, Value:by\n",
            "Key:18, Value:Lewis\n",
            "Key:18, Value:Carroll\n",
            "Key:27, Value:This\n",
            "Key:27, Value:eBook\n",
            "Key:27, Value:is\n",
            "Key:27, Value:for\n",
            "Key:27, Value:the\n",
            "Key:27, Value:use\n",
            "Key:27, Value:of\n",
            "Key:27, Value:anyone\n",
            "Key:27, Value:anywhere\n",
            "Key:27, Value:at\n",
            "Key:27, Value:no\n",
            "Key:27, Value:cost\n",
            "Key:27, Value:and\n",
            "Key:27, Value:with\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Action - write the RDD to a text file\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
        "\n",
        "#Creates Empty RDD\n",
        "emptyRDD = spark.sparkContext.emptyRDD()\n",
        "print(emptyRDD)\n",
        "\n",
        "#Diplays\n",
        "#EmptyRDD[188] at emptyRDD"
      ],
      "metadata": {
        "id": "oFYwz_dw_aqy",
        "outputId": "9a60df5f-1f10-4fbf-eb62-98a19f92a66a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EmptyRDD[426] at emptyRDD at NativeMethodAccessorImpl.java:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create Schema\n",
        "from pyspark.sql.types import StructType,StructField, StringType\n",
        "schema = StructType([\n",
        "  StructField('firstname', StringType(), True),\n",
        "  StructField('middlename', StringType(), True),\n",
        "  StructField('lastname', StringType(), True)\n",
        "  ])"
      ],
      "metadata": {
        "id": "oO4mAIZT_aoa"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create empty DataFrame from empty RDD\n",
        "df = spark.createDataFrame(emptyRDD,schema)\n",
        "df.printSchema()\n"
      ],
      "metadata": {
        "id": "dZwwM0AhBaxp",
        "outputId": "36dad3dc-3103-49e8-e26b-c349f7c3d7ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- firstname: string (nullable = true)\n",
            " |-- middlename: string (nullable = true)\n",
            " |-- lastname: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert empty RDD to Dataframe\n",
        "df1 = emptyRDD.toDF(schema)\n",
        "df1.printSchema()"
      ],
      "metadata": {
        "id": "_FU-807JBavS",
        "outputId": "7332f8f3-4699-4a18-e1c5-f14fd6ae234c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- firstname: string (nullable = true)\n",
            " |-- middlename: string (nullable = true)\n",
            " |-- lastname: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create empty DataFrame directly.\n",
        "df2 = spark.createDataFrame([], schema)\n",
        "df2.printSchema()"
      ],
      "metadata": {
        "id": "qpLS8EAtBatK",
        "outputId": "0ff626f0-8006-4ac1-9a2c-54b2eae464fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- firstname: string (nullable = true)\n",
            " |-- middlename: string (nullable = true)\n",
            " |-- lastname: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create empty DatFrame with no schema (no columns)\n",
        "df3 = spark.createDataFrame([], StructType([]))\n",
        "df3.printSchema()"
      ],
      "metadata": {
        "id": "1OfS4k5NBaq4",
        "outputId": "ea0a239f-d5f6-4494-b900-947d53bbc297",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MbEf7EcrBaof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c_nb-AYTBamS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Colaboratory chào mừng bạn!",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}